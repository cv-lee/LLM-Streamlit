import warnings
import streamlit as st
from streamlit_option_menu import option_menu
from models import load_llm, use_llm, load_lmm, use_lmm
from config.config import load_session_state

warnings.filterwarnings("ignore")


def main():
    config_path = "./config/config.json"
    load_session_state(config_path)

    st.set_page_config(
        page_title="",
        layout="wide",
        initial_sidebar_state="collapsed",
    )

    st.markdown(
        "<h1 style='text-align: center; background-color: #000045; color: #ece5f6'>AI Playground</h1>",
        unsafe_allow_html=True,
    )
    st.markdown(
        "<h4 style='text-align: center; background-color: #000045; color: #ece5f6'>Ask Anything you want</h4>",
        unsafe_allow_html=True,
    )
    st.markdown("<br>", unsafe_allow_html=True)

    with st.sidebar:
        model_task = option_menu(
            "Menu",
            ["ì±„íŒ…", "ìš”ì•½", "ìº¡ì°¨ í•´ë…"],
            icons=["house", "kanban", "bi bi-robot"],
            menu_icon="app-indicator",
            default_index=0,
            styles={
                "container": {"padding": "4!important", "background-color": "#fafafa"},
                "icon": {"color": "black", "font-size": "25px"},
                "nav-link": {
                    "font-size": "16px",
                    "text-align": "left",
                    "margin": "0px",
                    "--hover-color": "#fafafa",
                },
                "nav-link-selected": {"background-color": "#08c7b4"},
            },
        )

    st.subheader(f"ğŸ‘» {model_task}í•˜ê¸°", divider="rainbow")
    model_type = st.radio(
        label="ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
        options=["Fylee", "GPT-4", "Bard"],
        index=0,
        horizontal=True,
    )
    st.markdown("")

    if model_task == "ì±„íŒ…":
        prompt = st.text_area("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        prompt = st.session_state.chat_prompt.format(prompt)

        if st.button("ë‹µë³€ ìƒì„±"):
            load_llm()
            with st.spinner("ë‹µë³€ ìƒì„±ì¤‘..."):
                answer = use_llm(prompt)
                st.success("ë‹µë³€ ìƒì„±ì™„ë£Œ!")
                st.text("ë‹µë³€:")
                st.write(answer)

    elif model_task == "ìš”ì•½":
        prompt = st.text_area("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        prompt = st.session_state.summary_prompt.format(prompt)

        if st.button("ë‹µë³€ ìƒì„±"):
            load_llm()
            with st.spinner("ë‹µë³€ ìƒì„±ì¤‘..."):
                answer = use_llm(prompt)
                st.success("ë‹µë³€ ìƒì„±ì™„ë£Œ!")
                st.text("ë‹µë³€:")
                st.write(answer)

    else:
        image_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["png", "jpg"])
        prompt = st.text_area("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", value="Decode captcha letters in image.")
        prompt = st.session_state.captcha_prompt.format(prompt)

        if st.button("ìº¡ì°¨ í•´ë…"):
            load_lmm()
            with st.spinner("ìº¡ì°¨ í•´ë…ì¤‘..."):
                answer = use_lmm(prompt, image_file)
                st.success("ìº¡ì°¨ í•´ë…ì™„ë£Œ!")
                st.text("í•´ë… ê²°ê³¼:")
                st.write(answer)


if __name__ == "__main__":
    main()
